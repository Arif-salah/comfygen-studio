{
  "3": {
    "inputs": {
      "seed": [
        "74",
        0
      ],
      "steps": 8,
      "cfg": 1,
      "sampler_name": "ddim",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "161",
        0
      ],
      "positive": [
        "11",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "kokioIllu_v20XL.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "5": {
    "inputs": {
      "width": 1344,
      "height": 768,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "7": {
    "inputs": {
      "text": "(low quality, worst quality:1.4), (monochrome, grayscale:1.2), bad anatomy, bad hands, mutation, deformed, blurry, watermark, text, error, cropped, out of frame, jpeg artifacts, extra limbs, ugly, fat, obese",
      "clip": [
        "161",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "31",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "11": {
    "inputs": {
      "text": [
        "17",
        0
      ],
      "clip": [
        "161",
        1
      ]
    },
    "class_type": "Text to Conditioning",
    "_meta": {
      "title": "Text to Conditioning"
    }
  },
  "14": {
    "inputs": {
      "root_dir": "input",
      "file": "file.txt",
      "append": "append",
      "insert": true,
      "text": [
        "17",
        0
      ]
    },
    "class_type": "SaveText|pysssss",
    "_meta": {
      "title": "Save Text üêç"
    }
  },
  "17": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "true",
      "text_a": [
        "18",
        0
      ],
      "text_b": [
        "10:1",
        0
      ],
      "text_c": [
        "10:0",
        0
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "18": {
    "inputs": {
      "text": "(masterpiece, best quality, ultra-detailed, 8k),incredibly_absurdres, highres"
    },
    "class_type": "ttN text",
    "_meta": {
      "title": "text"
    }
  },
  "25": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "29": {
    "inputs": {
      "upscale_method": "bilinear",
      "scale_by": 1.5,
      "samples": [
        "3",
        0
      ]
    },
    "class_type": "LatentUpscaleBy",
    "_meta": {
      "title": "Upscale Latent By"
    }
  },
  "31": {
    "inputs": {
      "seed": [
        "74",
        0
      ],
      "steps": 8,
      "cfg": 2,
      "sampler_name": "ddim",
      "scheduler": "normal",
      "denoise": 0.5,
      "model": [
        "161",
        0
      ],
      "positive": [
        "11",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "29",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "32": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "33": {
    "inputs": {
      "images": [
        "32",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "74": {
    "inputs": {
      "seed": 635531996634171
    },
    "class_type": "Seed (rgthree)",
    "_meta": {
      "title": "Seed (rgthree)"
    }
  },
  "119": {
    "inputs": {
      "images": [
        "8",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "133": {
    "inputs": {
      "guide_size": 1024,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": [
        "74",
        0
      ],
      "steps": 8,
      "cfg": 1,
      "sampler_name": "ddim",
      "scheduler": "normal",
      "denoise": 0.5,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5,
      "bbox_dilation": 10,
      "bbox_crop_factor": 3,
      "sam_detection_hint": "center-1",
      "sam_dilation": 0,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7000000000000001,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "tiled_encode": false,
      "tiled_decode": false,
      "image": [
        "8",
        0
      ],
      "model": [
        "161",
        0
      ],
      "clip": [
        "161",
        1
      ],
      "vae": [
        "4",
        2
      ],
      "positive": [
        "11",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "bbox_detector": [
        "141",
        0
      ],
      "sam_model_opt": [
        "140",
        0
      ],
      "segm_detector_opt": [
        "141",
        1
      ],
      "detailer_hook": [
        "136",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "FaceDetailer"
    }
  },
  "136": {
    "inputs": {
      "mode": "768x768"
    },
    "class_type": "CoreMLDetailerHookProvider",
    "_meta": {
      "title": "CoreMLDetailerHookProvider"
    }
  },
  "137": {
    "inputs": {
      "images": [
        "133",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "140": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAMLoader (Impact)"
    }
  },
  "141": {
    "inputs": {
      "model_name": "bbox/yolov10m-face.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "142": {
    "inputs": {
      "mask": [
        "133",
        3
      ]
    },
    "class_type": "MaskPreview+",
    "_meta": {
      "title": "üîß Mask Preview"
    }
  },
  "143": {
    "inputs": {
      "images": [
        "133",
        1
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "144": {
    "inputs": {
      "images": [
        "133",
        2
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "149": {
    "inputs": {
      "amount": 0.8,
      "image": [
        "133",
        0
      ]
    },
    "class_type": "ImageCASharpening+",
    "_meta": {
      "title": "üîß Image Contrast Adaptive Sharpening"
    }
  },
  "157": {
    "inputs": {
      "model_name": "u2net",
      "image": [
        "149",
        0
      ]
    },
    "class_type": "Image Remove Background (rembg)",
    "_meta": {
      "title": "Rembg(Batch)"
    }
  },
  "158": {
    "inputs": {
      "images": [
        "157",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "159": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "149",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "161": {
    "inputs": {
      "lora_stack": [
        "163",
        0
      ],
      "model": [
        "4",
        0
      ],
      "optional_clip": [
        "25",
        0
      ]
    },
    "class_type": "easy loraStackApply",
    "_meta": {
      "title": "Easy Apply LoraStack"
    }
  },
  "163": {
    "inputs": {
      "input_mode": "simple",
      "lora_count": 4,
      "lora_name_1": "hinaPonyRealistic_v4-rev4-rank16.safetensors",
      "lora_wt_1": 0,
      "model_str_1": 1,
      "clip_str_1": 1,
      "lora_name_2": "None",
      "lora_wt_2": 1,
      "model_str_2": 1,
      "clip_str_2": 1,
      "lora_name_3": "None",
      "lora_wt_3": 1,
      "model_str_3": 1,
      "clip_str_3": 1,
      "lora_name_4": "None",
      "lora_wt_4": 1,
      "model_str_4": 1,
      "clip_str_4": 1,
      "lora_name_5": "None",
      "lora_wt_5": 1,
      "model_str_5": 1,
      "clip_str_5": 1,
      "lora_name_6": "None",
      "lora_wt_6": 1,
      "model_str_6": 1,
      "clip_str_6": 1,
      "lora_name_7": "None",
      "lora_wt_7": 1,
      "model_str_7": 1,
      "clip_str_7": 1,
      "lora_name_8": "None",
      "lora_wt_8": 1,
      "model_str_8": 1,
      "clip_str_8": 1,
      "lora_name_9": "None",
      "lora_wt_9": 1,
      "model_str_9": 1,
      "clip_str_9": 1,
      "lora_name_10": "None",
      "lora_wt_10": 1,
      "model_str_10": 1,
      "clip_str_10": 1,
      "lora_name_11": "None",
      "lora_wt_11": 1,
      "model_str_11": 1,
      "clip_str_11": 1,
      "lora_name_12": "None",
      "lora_wt_12": 1,
      "model_str_12": 1,
      "clip_str_12": 1,
      "lora_name_13": "None",
      "lora_wt_13": 1,
      "model_str_13": 1,
      "clip_str_13": 1,
      "lora_name_14": "None",
      "lora_wt_14": 1,
      "model_str_14": 1,
      "clip_str_14": 1,
      "lora_name_15": "None",
      "lora_wt_15": 1,
      "model_str_15": 1,
      "clip_str_15": 1,
      "lora_name_16": "None",
      "lora_wt_16": 1,
      "model_str_16": 1,
      "clip_str_16": 1,
      "lora_name_17": "None",
      "lora_wt_17": 1,
      "model_str_17": 1,
      "clip_str_17": 1,
      "lora_name_18": "None",
      "lora_wt_18": 1,
      "model_str_18": 1,
      "clip_str_18": 1,
      "lora_name_19": "None",
      "lora_wt_19": 1,
      "model_str_19": 1,
      "clip_str_19": 1,
      "lora_name_20": "None",
      "lora_wt_20": 1,
      "model_str_20": 1,
      "clip_str_20": 1,
      "lora_name_21": "None",
      "lora_wt_21": 1,
      "model_str_21": 1,
      "clip_str_21": 1,
      "lora_name_22": "None",
      "lora_wt_22": 1,
      "model_str_22": 1,
      "clip_str_22": 1,
      "lora_name_23": "None",
      "lora_wt_23": 1,
      "model_str_23": 1,
      "clip_str_23": 1,
      "lora_name_24": "None",
      "lora_wt_24": 1,
      "model_str_24": 1,
      "clip_str_24": 1,
      "lora_name_25": "None",
      "lora_wt_25": 1,
      "model_str_25": 1,
      "clip_str_25": 1,
      "lora_name_26": "None",
      "lora_wt_26": 1,
      "model_str_26": 1,
      "clip_str_26": 1,
      "lora_name_27": "None",
      "lora_wt_27": 1,
      "model_str_27": 1,
      "clip_str_27": 1,
      "lora_name_28": "None",
      "lora_wt_28": 1,
      "model_str_28": 1,
      "clip_str_28": 1,
      "lora_name_29": "None",
      "lora_wt_29": 1,
      "model_str_29": 1,
      "clip_str_29": 1,
      "lora_name_30": "None",
      "lora_wt_30": 1,
      "model_str_30": 1,
      "clip_str_30": 1,
      "lora_name_31": "None",
      "lora_wt_31": 1,
      "model_str_31": 1,
      "clip_str_31": 1,
      "lora_name_32": "None",
      "lora_wt_32": 1,
      "model_str_32": 1,
      "clip_str_32": 1,
      "lora_name_33": "None",
      "lora_wt_33": 1,
      "model_str_33": 1,
      "clip_str_33": 1,
      "lora_name_34": "None",
      "lora_wt_34": 1,
      "model_str_34": 1,
      "clip_str_34": 1,
      "lora_name_35": "None",
      "lora_wt_35": 1,
      "model_str_35": 1,
      "clip_str_35": 1,
      "lora_name_36": "None",
      "lora_wt_36": 1,
      "model_str_36": 1,
      "clip_str_36": 1,
      "lora_name_37": "None",
      "lora_wt_37": 1,
      "model_str_37": 1,
      "clip_str_37": 1,
      "lora_name_38": "None",
      "lora_wt_38": 1,
      "model_str_38": 1,
      "clip_str_38": 1,
      "lora_name_39": "None",
      "lora_wt_39": 1,
      "model_str_39": 1,
      "clip_str_39": 1,
      "lora_name_40": "None",
      "lora_wt_40": 1,
      "model_str_40": 1,
      "clip_str_40": 1,
      "lora_name_41": "None",
      "lora_wt_41": 1,
      "model_str_41": 1,
      "clip_str_41": 1,
      "lora_name_42": "None",
      "lora_wt_42": 1,
      "model_str_42": 1,
      "clip_str_42": 1,
      "lora_name_43": "None",
      "lora_wt_43": 1,
      "model_str_43": 1,
      "clip_str_43": 1,
      "lora_name_44": "None",
      "lora_wt_44": 1,
      "model_str_44": 1,
      "clip_str_44": 1,
      "lora_name_45": "None",
      "lora_wt_45": 1,
      "model_str_45": 1,
      "clip_str_45": 1,
      "lora_name_46": "None",
      "lora_wt_46": 1,
      "model_str_46": 1,
      "clip_str_46": 1,
      "lora_name_47": "None",
      "lora_wt_47": 1,
      "model_str_47": 1,
      "clip_str_47": 1,
      "lora_name_48": "None",
      "lora_wt_48": 1,
      "model_str_48": 1,
      "clip_str_48": 1,
      "lora_name_49": "None",
      "lora_wt_49": 1,
      "model_str_49": 1,
      "clip_str_49": 1
    },
    "class_type": "LoRA Stacker",
    "_meta": {
      "title": "LoRA Stacker"
    }
  },
  "10:0": {
    "inputs": {
      "text": ""
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Clothing"
    }
  },
  "10:1": {
    "inputs": {
      "text": ""
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "description"
    }
  }
}